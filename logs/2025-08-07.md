Diário Técnico: Do Erro à Detecção em Tempo Real com DetectNet na Jetson Orin Nano

Objetivo: Superar os desafios de configuração da Jetson Orin Nano (JetPack 6) para executar o DetectNet e, ao final, criar um script Python para vigilância automática.

Fase 1: Diagnóstico e Estratégia Inicial

    Problema: A tentativa de instalar manualmente as bibliotecas (PyTorch, NumPy, TensorRT) resultou em conflitos de versão e falhas.

    Decisão Estratégica: Abandonar a instalação manual. Adotar o método recomendado pela NVIDIA para JetPack 6, utilizando o repositório jetson-inference com containers Docker, para garantir um ambiente com dependências 100% compatíveis.

Fase 2: O Desafio do Container Docker

    Obstáculo 1: A Imagem Inexistente (manifest not found)

        Ocorrência: Ao executar docker/run.sh, o script tentou baixar uma imagem para a nossa versão específica do sistema (r36.4.4), que ainda não estava disponível publicamente.

        Tentativa de Solução 1 (Falha): Tentamos forçar o uso de uma imagem mais antiga e compatível (r36.3.0) com o comando docker/run.sh --image dustynv/jetson-inference:r36.3.0.

        Resultado: O terminal retornou WARN: Unknown option (ignored): --image. O script não reconhecia este argumento.

    Obstáculo 2: A Depuração do Script run.sh

        Ocorrência: O método para especificar a imagem correta era desconhecido. Para resolver, você compartilhou o conteúdo completo do script docker/run.sh.

        Análise: Ao revisar o código do script, identificamos na seção de ajuda que o argumento correto não era --image, mas sim --container.

        Solução Definitiva: Executamos o comando com o argumento correto:
        Bash

        docker/run.sh --container dustynv/jetson-inference:r36.3.0

        Resultado: SUCESSO. O Docker localizou e baixou a imagem do container, nos dando acesso ao ambiente de desenvolvimento correto.

Fase 3: Compilação e Execução

    Obstáculo 3: O sudo Fantasma (command not found)

        Ocorrência: Dentro do container, ao executar sudo make install, o comando falhou.

        Análise: O prompt do terminal (root@...) indicava que já possuíamos privilégios de superusuário.

        Solução: Removemos o sudo dos comandos, executando make install e ldconfig diretamente. A instalação foi concluída com sucesso.

    Obstáculo 4: A Sintaxe do detectnet

        Ocorrência: A primeira execução do programa (./detectnet ssd-mobilenet-v2 ...) falhou com um erro de "caminho de recurso inválido".

        Análise: O programa estava interpretando o nome do modelo como um arquivo de vídeo.

        Solução: Corrigimos a sintaxe para usar a flag --network, que especifica o modelo a ser carregado: ./detectnet --network=ssd-mobilenet-v2 ....

    Obstáculo 5: A Otimização do TensorRT (O "Falso Travamento")

        Ocorrência: Após o comando correto, o programa ficou parado por vários minutos, aparentando ter travado.

        Análise: Este é o comportamento esperado na primeira execução. O TensorRT estava realizando uma otimização única e intensiva do modelo para a GPU da Orin Nano.

        Solução: Apenas aguardar. Após a conclusão, o programa iniciou e a detecção de vídeo começou a rodar de forma fluida.

Fase 4: Sucesso e Criação do Código Final

    Validação do Sucesso: A execução do DetectNet diretamente no terminal demonstrou uma alta taxa de quadros por segundo (FPS), confirmando que a aceleração por GPU e a otimização do TensorRT foram bem-sucedidas.

    Desenvolvimento do Script Python: Para consolidar o aprendizado e criar uma solução prática, desenvolvemos o script detector_periodico.py. Este script:

        Utiliza as bibliotecas jetson_inference e jetson_utils de forma eficiente.

        Implementa a lógica de captura e análise em intervalos de tempo definidos.

        Identifica a classe "person" nas detecções.

        Cria um arquivo de log (detector_periodico.log) para registrar toda a atividade, incluindo alertas e possíveis erros, tornando a solução robusta e fácil de monitorar.

Conclusão Final: A jornada foi um exercício completo de troubleshooting em um ambiente de IA embarcada, passando por configuração de containers, depuração de scripts, sintaxe de comandos e, finalmente, desenvolvimento de uma aplicação em Python. Cada obstáculo superado contribuiu para o sucesso e a robustez da solução final.
